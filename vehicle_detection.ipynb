{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Get Spatial binning return 32*32 features\n",
    "#----------------------------------------------\n",
    "\n",
    "def spatial_bin_feat(img,color_space = 'RGB',size = (32,32)):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "            feature_img2 = feature_img[:,:,2]\n",
    "        elif color_space == 'HLS':\n",
    "            feature_img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "            feature_img1 = feature_img[:,:,0]\n",
    "            feature_img2 = feature_img[:,:,2]\n",
    "#             plt.title(feature_img[:,:,1].shape)\n",
    "#             plt.imshow(feature_img[:,:,1],cmap = 'gray')\n",
    "        elif color_space == 'YUV':\n",
    "            feature_img = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
    "            feature_img2 = feature_img[:,:,0]\n",
    "    else:\n",
    "        feature_img = np.copy(img)\n",
    "#     print(feature_img.shape)\n",
    "    features = cv2.resize(feature_img2,size).ravel()\n",
    "   # print(features.shape)\n",
    "    return features\n",
    "\n",
    "#----------------------------------------------\n",
    "# Get Color histogram features\n",
    "#----------------------------------------------\n",
    "def color_hist(img,nbins =32,bins_range = (0,256)):\n",
    "    # histogram if RGB channels\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    h_hist = np.histogram(img[:,:,0],bins = nbins,range = bins_range)\n",
    "    l_hist = np.histogram(img[:,:,1],bins = nbins,range = bins_range)\n",
    "    s_hist = np.histogram(img[:,:,2],bins = nbins,range = bins_range)\n",
    "    \n",
    "    h_features = np.concatenate((h_hist[0],l_hist[0],s_hist[0]))\n",
    "#     h_features = np.concatenate((rhist[0],bhist[0]))\n",
    "    return h_features\n",
    "\n",
    "#----------------------------------------------\n",
    "# Get HOG features\n",
    "#----------------------------------------------\n",
    "def hog_features(img,orient,pix_per_cell,cell_per_block,vis = False ,feature_vec = True):\n",
    "    ret_list = hog(img,orientations = orient ,pixels_per_cell = (pix_per_cell,pix_per_cell),cells_per_block = (cell_per_block,cell_per_block),block_norm= 'L2-Hys', transform_sqrt=False, visualise= vis, feature_vector= feature_vec)\n",
    "    # name returns explicitly\n",
    "    hog_features = ret_list[0]\n",
    "    if vis:\n",
    "        hog_image = ret_list[1]\n",
    "        return hog_features.ravel(), hog_image\n",
    "    else:\n",
    "        return hog_features.ravel()\n",
    "    \n",
    "#----------------------------------------------\n",
    "# Get Combined features\n",
    "#----------------------------------------------\n",
    "def get_all_features(t_img):\n",
    "    sp_size = (20,20)\n",
    "    sb_features = spatial_bin_feat(t_img,'YUV',sp_size)\n",
    "    \n",
    "#     hist_features = color_hist(t_img)\n",
    "    \n",
    "    hls_img = cv2.cvtColor(t_img,cv2.COLOR_RGB2HLS)\n",
    "    s_img = hls_img[:,:,2]\n",
    "    sh_features, shog_image = hog_features(s_img, orient= 10, \n",
    "                            pix_per_cell= 16, cell_per_block= 2, \n",
    "                            vis=True, feature_vec=False)\n",
    "    \n",
    "    yuv_img = cv2.cvtColor(t_img,cv2.COLOR_RGB2YUV)\n",
    "    y_img = yuv_img[:,:,0]\n",
    "    yh_features, yhog_image = hog_features(y_img, orient= 10, \n",
    "                            pix_per_cell= 16, cell_per_block= 2, \n",
    "                            vis=True, feature_vec=False)\n",
    "    comb_feature = np.concatenate((sh_features,yh_features,sb_features))\n",
    "#     comb_feature = np.concatenate((hist_features,h_features))\n",
    "    #print(len(comb_feature))\n",
    "    return comb_feature\n",
    "#     return comb_feature,shog_image,yhog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vehicle_paths = [\"non-vehicles/Extras/*.png\", \"non-vehicles/GTI/*.png\"]\n",
    "\n",
    "vehicle_paths = [\"vehicles/GTI_Far/*.png\", \"vehicles/GTI_Left/*.png\", \"vehicles/GTI_Right/*.png\",\n",
    "                    \"vehicles/GTI_MiddleClose/*.png\", \"vehicles/KITTI_extracted/*.png\"]\n",
    "\n",
    "non_vehicle_filenames = []\n",
    "vehicle_filenames = []\n",
    "\n",
    "for path in non_vehicle_paths:\n",
    "    non_vehicle_filenames += glob.glob(path)\n",
    "    \n",
    "for path in vehicle_paths:\n",
    "    vehicle_filenames += glob.glob(path)\n",
    "    \n",
    "# print(non_vehicle_filenames[0])\n",
    "# print(vehicle_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"#Vehicles :\",len(vehicle_filenames),\"#Non-Vehicles:\",len(non_vehicle_filenames))\n",
    "# ## #Vehicles : 8792 #Non-Vehicles: 8968\n",
    "\n",
    "# nv_img = cv2.imread(non_vehicle_filenames[10])\n",
    "# nv_img = cv2.cvtColor(nv_img,cv2.COLOR_BGR2RGB)\n",
    "# _,shog_image,yhog_image = get_all_features(nv_img)\n",
    "# plt.subplot(2,3,1)\n",
    "# plt.title(\"Non vehicle\")\n",
    "# plt.imshow(nv_img)\n",
    "# plt.subplot(2,3,2)\n",
    "# plt.title(\"S-Channel HOG\")\n",
    "# plt.imshow(shog_image)\n",
    "# plt.subplot(2,3,3)\n",
    "# plt.title(\"Y-Channel HOG\")\n",
    "# plt.imshow(yhog_image)\n",
    "\n",
    "# v_img = cv2.imread(vehicle_filenames[10])\n",
    "# v_img = cv2.cvtColor(v_img,cv2.COLOR_BGR2RGB)\n",
    "# _,svhog_image,yvhog_image = get_all_features(v_img)\n",
    "# plt.subplot(2,3,4)\n",
    "# plt.title(\"Vehicle\")\n",
    "# plt.imshow(v_img)\n",
    "# plt.subplot(2,3,5)\n",
    "# plt.title(\"S-Channel HOG\")\n",
    "# plt.imshow(svhog_image)\n",
    "# plt.subplot(2,3,6)\n",
    "# plt.title(\"Y-Channel HOG\")\n",
    "# plt.imshow(yvhog_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.max(nv_img),np.min(nv_img)) #0.8117647 0.015686275\n",
    "# print(v_img.shape) #(64, 64, 3)\n",
    "all_img_features = []\n",
    "for idx in range(len(vehicle_filenames)):\n",
    "    # to get all the feature\n",
    "    v_img = cv2.imread(vehicle_filenames[idx])\n",
    "    v_img = cv2.cvtColor(v_img,cv2.COLOR_BGR2RGB)\n",
    "    img_feature = get_all_features(v_img)\n",
    "    img_feature = img_feature.tolist()\n",
    "    all_img_features.append(img_feature)\n",
    "# print(all_img_features.size)\n",
    "print(len(all_img_features))\n",
    "\n",
    "for nv_idx in range(len(non_vehicle_filenames)):\n",
    "    # to get all the feature\n",
    "    nv_img = cv2.imread(non_vehicle_filenames[nv_idx])\n",
    "    nv_img = cv2.cvtColor(nv_img,cv2.COLOR_BGR2RGB)\n",
    "    img_feature = get_all_features(nv_img)\n",
    "    img_feature = img_feature.tolist()\n",
    "    all_img_features.append(img_feature)\n",
    "    \n",
    "# one hot encoded vectors is_car = 1 if its a car\n",
    "is_car = np.ones(len(vehicle_filenames))\n",
    "is_car = is_car.tolist()\n",
    "# print(len(is_car))\n",
    "non_car = np.zeros(len(non_vehicle_filenames))\n",
    "non_car = non_car.tolist()\n",
    "is_car += non_car\n",
    "print(len(is_car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing feature vectors in pickle file\n",
    "import pickle\n",
    "output_f = open('features_t1.pkl','wb')\n",
    "output_h = open('onehot_t1.pkl','wb')\n",
    "pickle.dump(all_img_features,output_f)\n",
    "pickle.dump(is_car,output_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_file = open('features_t1.pkl','rb')\n",
    "h_file = open('onehot_t1.pkl','rb')\n",
    "X_pkl = pickle.load(f_file)\n",
    "Y_pkl = pickle.load(h_file)\n",
    "# print(len(X_train)) #17760\n",
    "# print(len(Y_train)) #17760\n",
    "X = np.vstack(X_pkl).astype(np.float64)\n",
    "y = np.hstack(Y_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# Training the SVN model\n",
    "#-----------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_model(X,y):\n",
    "    rand_state = np.random.randint(0,100)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = rand_state)\n",
    "\n",
    "    # fit a per column scalar\n",
    "    X_scalar = StandardScaler().fit(X_train)\n",
    "    #Apply the scalar  to X\n",
    "    scaled_X_train = X_scalar.transform(X_train)\n",
    "    scaled_X_test = X_scalar.transform(X_test)\n",
    "    #print(scaled_X_test)\n",
    "\n",
    "    svc = SVC(kernel = \"rbf\")\n",
    "    svc.fit(scaled_X_train,y_train)\n",
    "    return svc,X_scalar,scaled_X_train,scaled_X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "svc,X_scalar,_,scaled_X_test,y_test = train_model(X,y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(\"Train Accuracy :\",svc.score(scaled_X_train,y_train))\n",
    "# # Linear SVC\n",
    "# # Train Accuracy : 0.9985923423423423\n",
    "# # SVC with linear kernel\n",
    "# # Train Accuracy : 0.9995777027027027\n",
    "# # SVC with rbf kernel\n",
    "# # Train Accuracy : 0.9773367117117117\n",
    "print(\"Test Accuracy :\",svc.score(scaled_X_test,y_test))\n",
    "# Linear SVC\n",
    "# Test Accuracy : 0.9293355855855856\n",
    "# SVC with linear kernel\n",
    "# Test Accuracy : 0.928490990990991\n",
    "# SVC with rbf kernel\n",
    "# Test Accuracy : 0.9710022522522522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t1 = open('model_t1.pkl','wb')\n",
    "scalar_m = open('scalar_x_t1.pkl','wb')\n",
    "pickle.dump(svc,model_t1)\n",
    "pickle.dump(X_scalar,scalar_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "model_file = open('model_t1.pkl','rb')\n",
    "sklr_file = open('scalar_x_t1.pkl','rb')\n",
    "svc = pickle.load(model_file)\n",
    "X_scalar = pickle.load(sklr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-----------------------------------\n",
    "# #   Predicting (for Y=Testing)\n",
    "# #-----------------------------------\n",
    "# print(len(scaled_X_test[0]))\n",
    "t1 = time.time()\n",
    "svc.predict(scaled_X_test[0:200])\n",
    "print(time.time()- t1) #2.0156702995300293\n",
    "\n",
    "\n",
    "# # ridx = np.random.randint(0,len(vehicle_filenames))\n",
    "# ridx = np.random.randint(0,len(non_vehicle_filenames))\n",
    "# print(ridx,len(vehicle_filenames))\n",
    "# # pred_img = plt.imread(vehicle_filenames[ridx])\n",
    "# pred_img = plt.imread(non_vehicle_filenames[ridx])\n",
    "# img_feat = get_all_features(pred_img)\n",
    "# scaled_img_feat = X_scalar.transform(img_feat.reshape(1,-1))\n",
    "\n",
    "# p_start_time = time.time()\n",
    "# ret = svc.predict(scaled_img_feat)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - p_start_time))\n",
    "# print(ret)\n",
    "# # for false images\n",
    "\n",
    "# if ret == 1.0:\n",
    "#     plt.imshow( plt.imread(non_vehicle_filenames[ridx]),cmap = 'gray')#4534 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,23,44])\n",
    "# a = a.tolist()\n",
    "# print(type(a))\n",
    "# x = []\n",
    "# t = [1,2]\n",
    "# p = [1,3]\n",
    "# x.append(t)\n",
    "# x.append(p)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Windowing Functions\n",
    "#--------------------------------------------------\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None],xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=1):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "def all_windows(img):\n",
    "    test_img = np.copy(img)\n",
    "#     x_start_stop=[640,860]\n",
    "#     y_start_stop=[380, 460]\n",
    "#     w1 = slide_window(test_img, x_start_stop, y_start_stop,xy_window=(64, 64), xy_overlap=(0.7, 0.7))\n",
    "    x_start_stop=[570,1050]\n",
    "    y_start_stop=[400, 480]\n",
    "    w1 = slide_window(test_img, x_start_stop, y_start_stop,xy_window=(80, 80), xy_overlap=(0.8, 0.8))\n",
    "    y_start_stop=[380, 520]\n",
    "    \n",
    "    x_start_stop=[570,1280]\n",
    "    w1.extend(slide_window(test_img, x_start_stop, y_start_stop,xy_window=(100, 100), xy_overlap=(0.7, 0.7)))\n",
    "    y_start_stop=[410, 590]\n",
    "    w1.extend(slide_window(test_img, x_start_stop, y_start_stop,xy_window=(120, 120), xy_overlap=(0.7, 0.7)))\n",
    "    \n",
    "    x_start_stop=[1115,1280]\n",
    "    y_start_stop=[370, 500]\n",
    "    w1.extend(slide_window(test_img, x_start_stop, y_start_stop,xy_window=(80, 80), xy_overlap=(0.8, 0.8)))\n",
    "    \n",
    "    x_start_stop=[1090,1280]\n",
    "    y_start_stop=[360, 520]\n",
    "    w1.extend(slide_window(test_img, x_start_stop, y_start_stop,xy_window=(135, 120), xy_overlap=(0.7, 0.7)))\n",
    "    w1.extend(slide_window(test_img, x_start_stop, y_start_stop,xy_window=(140, 140), xy_overlap=(0.7, 0.7)))\n",
    "    windows_img = draw_boxes(test_img,w1)\n",
    "    #plt.imshow(windows_img)\n",
    "#     plt.imsave('windowsNew.jpg',windows_img)\n",
    "    return w1\n",
    "\n",
    "# passed args source image,Classifier object,all windows\n",
    "def search_window_obj(img,svc,windows):\n",
    "    car_windows = []\n",
    "#     count = 0\n",
    "    for window in windows:\n",
    "        # Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        features = get_all_features(test_img)\n",
    "        scaled_feature = X_scalar.transform(features.reshape(1,-1))\n",
    "        # predict using classifier\n",
    "        prediction = svc.predict(scaled_feature)\n",
    "        \n",
    "        if prediction == 1:\n",
    "#             count+=1\n",
    "            car_windows.append(window)\n",
    "#     print('matched windows:',count)\n",
    "    return car_windows\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels,thrshold):\n",
    "    # Iterate through all detected cars\n",
    "    nboxes = 0\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        if ((np.max(nonzerox) - np.min(nonzerox)) > thrshold[0]) & ((np.max(nonzeroy) - np.min(nonzeroy)) > thrshold[1]):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "            nboxes+=1\n",
    "    # Return the image\n",
    "#     print(nboxes)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------for plotting windows\n",
    "test_img = plt.imread('./test_images/test4.jpg')\n",
    "plt.imshow(test_img)\n",
    "windows = all_windows(test_img)\n",
    "windows_img = draw_boxes(test_img,windows)\n",
    "# plt.imshow(windows_img)\n",
    "plt.imsave('windows.jpg',windows_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class object_detection:\n",
    "    def __init__(self):\n",
    "        self.coll_heatmap = []\n",
    "    def pipeline(self,frame_img):\n",
    "        windows = all_windows(frame_img)\n",
    "        hot_window = search_window_obj(frame_img,svc,windows)\n",
    "#         print(len(hot_window))\n",
    "#         windows_img = draw_boxes(frame_img,hot_window)\n",
    "#         plt.imsave('detected.jpg',windows_img)\n",
    "\n",
    "        heat = np.zeros_like(frame_img[:,:,0]).astype(np.float)\n",
    "\n",
    "        # Add heat to each box in box list\n",
    "        heat = add_heat(heat,hot_window)\n",
    "        \n",
    "        self.coll_heatmap.append(heat)\n",
    "        self.coll_heatmap = self.coll_heatmap[-7:] \n",
    "        \n",
    "        heat = sum(self.coll_heatmap)/len(self.coll_heatmap)\n",
    "        # Apply threshold to help remove false positives\n",
    "        heat = apply_threshold(heat,4)\n",
    "\n",
    "        # Visualize the heatmap when displaying    \n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(heatmap)\n",
    "        # print(type(labels))\n",
    "\n",
    "        # to remove false positives\n",
    "\n",
    "        heat_thrshold = [50,50]\n",
    "        draw_img = draw_labeled_bboxes(np.copy(frame_img), labels ,heat_thrshold)\n",
    "    #     heatmap = np.vstack((heatmap,heatmap,heatmap))\n",
    "    #     draw_img = cv2.addWeighted(draw_img,1.0,heatmap,0.5,0)\n",
    "        return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f_img = plt.imread('./test_images/snap6.jpg')\n",
    "# objt = object_detection()\n",
    "# ret_img = objt.pipeline(f_img)\n",
    "# plt.imshow(ret_img)\n",
    "# plt.imsave('boxcar.jpg',ret_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML\n",
    "# video_output = './processed_video.mp4'\n",
    "# clip1 = VideoFileClip(\"./test_video.mp4\")\n",
    "# obj_clip = clip1.fl_image(pipeline)\n",
    "# %time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_img = plt.imread('./test_images/snap1.jpg')\n",
    "t_obj = object_detection()\n",
    "ret_img = t_obj.pipeline(f_img)\n",
    "plt.imshow(ret_img)\n",
    "plt.imsave('car_position.jpg',ret_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline testing\n",
    "f_img = plt.imread('./test_images/test6.jpg')\n",
    "ret_img = pipeline(f_img)\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Image6\")\n",
    "plt.imshow(f_img)\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Heatmap\")\n",
    "plt.imshow(heatmap,cmap = 'hot')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Detection\")\n",
    "plt.imshow(ret_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- for testing\n",
    "# from scipy.ndimage.measurements import label\n",
    "# frame_img = plt.imread('./test_images/test1.jpg')\n",
    "# # t1 = time.time()\n",
    "# windows = all_windows(frame_img)\n",
    "# print('Total windows',len(windows))\n",
    "# hot_window = search_window_obj(frame_img,svc,windows)\n",
    "# # print('Total matched windows',len(hot_window))\n",
    "# windows_img = draw_boxes(frame_img,hot_window)\n",
    "# plt.imsave('detected.jpg',windows_img)\n",
    "\n",
    "# heat = np.zeros_like(frame_img[:,:,0]).astype(np.float)\n",
    "\n",
    "# # Add heat to each box in box list\n",
    "# heat = add_heat(heat,hot_window)\n",
    "    \n",
    "# # Apply threshold to help remove false positives\n",
    "# heat = apply_threshold(heat,5)\n",
    "\n",
    "# # Visualize the heatmap when displaying    \n",
    "# heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# # Find final boxes from heatmap using label function\n",
    "# labels = label(heatmap)\n",
    "# # print(type(labels))\n",
    "\n",
    "# # to remove false positives\n",
    "# heat_thrshold = [60,60]\n",
    "# draw_img = draw_labeled_bboxes(np.copy(frame_img), labels ,heat_thrshold)\n",
    "# # print('time taken for one image :',time.time()-t1) #time taken for one image : 13.113383054733276\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(draw_img)\n",
    "# plt.title('Car Positions')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(heatmap, cmap='hot')\n",
    "# plt.title('Heat Map')\n",
    "# fig.tight_layout()\n",
    "# plt.imsave('car_position.jpg',draw_img)\n",
    "# plt.imsave('heatmap.jpg',heatmap)\n",
    "# plt.title('Heat Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_img = plt.imread('./test_images/test4.jpg')\n",
    "# frame_img = cv2.cvtColor(frame_img,cv2.COLOR_RGB2YUV)\n",
    "# plt.imshow(frame_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./test_video_output.mp4\n",
      "[MoviePy] Writing video ./test_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [04:33<00:06,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./test_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "video_output = './test_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"./test_video.mp4\")\n",
    "od_obj = object_detection()\n",
    "obj_clip = clip1.fl_image(od_obj.pipeline)\n",
    "%time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_output_4950.mp4\n",
      "[MoviePy] Writing video ./project_video_output_4950.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [04:31<00:00,  9.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_output_4950.mp4 \n",
      "\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML\n",
    "\n",
    "\n",
    "# video_output = './project_video_output_4950.mp4'\n",
    "# clip1 = VideoFileClip(\"./project_video.mp4\").subclip(49, None)\n",
    "# od_obj = object_detection()\n",
    "# obj_clip = clip1.fl_image(od_obj.pipeline)\n",
    "# %time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_output_4042.mp4\n",
      "[MoviePy] Writing video ./project_video_output_4042.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▍ | 50/51 [05:53<00:07,  7.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_output_4042.mp4 \n",
      "\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "# video_output = './project_video_output_4042.mp4'\n",
    "# clip1 = VideoFileClip(\"./project_video.mp4\").subclip(40, 42)\n",
    "# od_obj = object_detection()\n",
    "# obj_clip = clip1.fl_image(od_obj.pipeline)\n",
    "# %time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_output_1821.mp4\n",
      "[MoviePy] Writing video ./project_video_output_1821.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████▉ | 75/76 [09:07<00:06,  6.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_output_1821.mp4 \n",
      "\n",
      "Wall time: 9min 11s\n"
     ]
    }
   ],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML\n",
    "# video_output = './project_video_output_1821.mp4'\n",
    "# clip1 = VideoFileClip(\"./project_video.mp4\").subclip(18, 21)\n",
    "# od_obj = object_detection()\n",
    "# obj_clip = clip1.fl_image(od_obj.pipeline)\n",
    "# %time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_output1.mp4\n",
      "[MoviePy] Writing video ./project_video_output1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 1260/1261 [2:08:45<00:05,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_output1.mp4 \n",
      "\n",
      "Wall time: 2h 8min 48s\n"
     ]
    }
   ],
   "source": [
    "video_output = './project_video_output1.mp4'\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "od_obj = object_detection()\n",
    "obj_clip = clip1.fl_image(od_obj.pipeline)\n",
    "%time obj_clip.write_videofile(video_output,audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class img_frame:\n",
    "#     y = 0\n",
    "#     def save_img(self,img):\n",
    "#         img_frame.y = img_frame.y+1\n",
    "#         img_no = './frame_imgs/'+str(img_frame.y)+'.jpg'\n",
    "#         plt.imsave(img_no,img)\n",
    "#         return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML\n",
    "# import matplotlib.pyplot as plt\n",
    "# clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "# ifo = img_frame()\n",
    "# t = clip1.fl_image(ifo.save_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
